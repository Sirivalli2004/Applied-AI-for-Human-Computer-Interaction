{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FaYBUUToQ_s-","outputId":"818d2db1-0e10-41f2-acde-816346408929"},"outputs":[{"output_type":"stream","name":"stdout","text":["Victory\n","Ok\n","Power\n","Love\n","validVictory\n","validLove\n","validPower\n","validOk\n","Found 9600 images belonging to 4 classes.\n","Found 2410 images belonging to 4 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 0s 0us/step\n","58900480/58889256 [==============================] - 0s 0us/step\n","False\n","False\n","False\n","False\n","False\n","False\n","False\n","False\n","False\n","False\n","False\n","False\n","False\n","False\n","False\n","False\n","False\n","False\n","False\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","49/56 [=========================>....] - ETA: 5:22 - loss: 0.9731 - accuracy: 0.5996"]}],"source":["import os\n","import keras\n","import tensorflow as tf\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dropout, BatchNormalization, Dense, Flatten\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","\n","\n","train_directory = \"/content/drive/MyDrive/New folder/train1\"\n","training_folder = os.listdir(train_directory)\n","classes = []\n","\n","for folder in training_folder:\n","    classes.append(folder)\n","    print(folder)\n","\n","validation_directory = \"/content/drive/MyDrive/New folder/validation1\"\n","validation_folder = os.listdir(validation_directory)\n","classes = []\n","\n","for folder in validation_folder:\n","    classes.append(folder)\n","    print(folder)    \n","\n","num_classes = 4\n","\n","Img_Height = 200\n","Img_width = 200\n","\n","batch_size = 128\n","\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","                                   rotation_range=30,\n","                                   shear_range=0.3,\n","                                   zoom_range=0.3,\n","                                   width_shift_range=0.4,\n","                                   height_shift_range=0.4,\n","                                   horizontal_flip=True,\n","                                   fill_mode='nearest')\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(train_directory,\n","                                                    target_size=(Img_Height, Img_width),\n","                                                    batch_size=batch_size,\n","                                                    class_mode='categorical',\n","                                                    shuffle=True)\n","\n","validation_generator = validation_datagen.flow_from_directory(validation_directory,\n","                                                             target_size=(Img_Height, Img_width),\n","                                                             batch_size=batch_size,\n","                                                             class_mode='categorical',\n","                                                             shuffle=True)\n","\n","VGG16_MODEL = VGG16(input_shape=(Img_width, Img_Height, 3), include_top=False, weights='imagenet')\n","\n","for layers in VGG16_MODEL.layers: \n","    layers.trainable=False\n","\n","for layers in VGG16_MODEL.layers:\n","    print(layers.trainable)\n","\n","# Input layer\n","input_layer = VGG16_MODEL.output\n","\n","# Convolutional Layer\n","Conv1 = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='valid',\n","               data_format='channels_last', activation='relu', \n","               kernel_initializer=keras.initializers.he_normal(seed=0), \n","               name='Conv1')(input_layer)\n","\n","# MaxPool Layer\n","Pool1 = MaxPool2D(pool_size=(2,2),strides=(2,2),padding='valid', \n","                  data_format='channels_last',name='Pool1')(Conv1)\n","\n","# Flatten\n","flatten = Flatten(data_format='channels_last',name='Flatten')(Pool1)\n","\n","# Fully Connected layer-1\n","FC1 = Dense(units=30, activation='relu', \n","            kernel_initializer=keras.initializers.glorot_normal(seed=32), \n","            name='FC1')(flatten)\n","\n","# Fully Connected layer-2\n","FC2 = Dense(units=30, activation='relu', \n","            kernel_initializer=keras.initializers.glorot_normal(seed=33),\n","            name='FC2')(FC1)\n","\n","# Output layer\n","Out = Dense(units=num_classes, activation='softmax', \n","            kernel_initializer=keras.initializers.glorot_normal(seed=3), \n","            name='Output')(FC2)\n","\n","model_gesture = Model(inputs=VGG16_MODEL.input,outputs=Out)\n","\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","from tensorflow.keras.callbacks import TensorBoard\n","\n","checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/New folder/gestt.h5\", monitor='accuracy', verbose=1,\n","                              save_best_only=True, mode='auto', period=1)\n","\n","reduce = ReduceLROnPlateau(monitor='accuracy', factor=0.2, patience=10, \n","                           min_lr=0.0001, verbose = 1)\n","\n","logdir='logs'\n","tensorboard_Visualization = TensorBoard(log_dir=logdir, histogram_freq=False)\n","\n","\n","train_samples = 7200\n","validation_samples = 1810 \n","\n","epochs = 50\n","\n","batch_size = 128\n","\n","model_gesture.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(lr=0.001),\n","              metrics=['accuracy']\n","              )\n","           \n","model_gesture.fit(train_generator,\n","           steps_per_epoch = train_samples//batch_size,\n","           epochs = epochs,\n","           callbacks = [checkpoint, reduce, tensorboard_Visualization],\n","           validation_data = validation_generator,\n","           validation_steps = validation_samples//batch_size)\n","\n","# model_gesture.fit(train_generator,\n","#            steps_per_epoch = train_samples/batch_size,\n","#            epochs = epochs,\n","#            callbacks = [checkpoint, reduce, tensorboard_Visualization],\n","#            validation_data = validation_generator,\n","#            validation_steps = validation_samples/batch_size)\n","model_gesture.save('/content/drive/MyDrive/New folder/gestu.h5')   \n"]}],"metadata":{"colab":{"name":"gesture train.ipynb","provenance":[],"mount_file_id":"1aA0OK7hIUO9hcYaKjiHnUCWV1-dHHLn0","authorship_tag":"ABX9TyO/yMLspdOp7pztlT0Luysu"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}